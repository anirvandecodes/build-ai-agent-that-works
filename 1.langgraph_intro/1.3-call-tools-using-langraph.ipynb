{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a03cb8ac-5eda-46a7-baf5-372791fe29a4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import random\n",
    "from typing import Literal, TypedDict\n",
    "from langchain_core.messages import AnyMessage, HumanMessage\n",
    "from langgraph.graph.message import add_messages\n",
    "from typing_extensions import Annotated\n",
    "from databricks_langchain import ChatDatabricks\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.prebuilt import ToolNode, tools_condition\n",
    "\n",
    "\n",
    "from langgraph.graph import MessagesState\n",
    "\n",
    "# load_dotenv()\n",
    "\n",
    "\n",
    "import mlflow\n",
    "mlflow.langchain.autolog()\n",
    "\n",
    "class State(MessagesState):\n",
    "    pass\n",
    "\n",
    "\n",
    "\n",
    "def multiply(a: int, b: int) -> int:\n",
    "    \"\"\"Multiply two numbers\"\"\"\n",
    "    \"\"\"Example:\n",
    "    >>> multiply(2, 3)\n",
    "    6\n",
    "    \"\"\"\n",
    "    \"\"\"Args:\n",
    "    a: int\n",
    "    b: int\n",
    "    \"\"\"\n",
    "    \"\"\"Returns:\n",
    "    int\n",
    "    \"\"\"\n",
    "    return a * b\n",
    "\n",
    "\n",
    "llm = ChatDatabricks(endpoint = \"databricks-gpt-oss-120b\")\n",
    "\n",
    "llm_with_tools = llm.bind_tools([multiply])\n",
    "\n",
    "def tool_calling_llm(state: State):\n",
    "    return {\"messages\": [llm_with_tools.invoke(state[\"messages\"])]}\n",
    "\n",
    "\n",
    "builder = StateGraph(State)\n",
    "builder.add_node(\"tool_calling_llm\", tool_calling_llm)\n",
    "builder.add_node(\"tools\", ToolNode([multiply]))\n",
    "\n",
    "\n",
    "builder.add_edge(START, \"tool_calling_llm\")\n",
    "builder.add_conditional_edges(\"tool_calling_llm\", tools_condition)\n",
    "builder.add_edge(\"tools\", \"tool_calling_llm\")\n",
    "\n",
    "graph = builder.compile()\n",
    "\n",
    "result = graph.invoke({\"messages\": [HumanMessage(\"Hello,what is the weather in Tokyo? and what is 2 * 3?\")]})\n",
    "\n",
    "\n",
    "for i, message in enumerate(result[\"messages\"]):\n",
    "    print(f\"Message {i+1} ({type(message).__name__}): {message.content}\")\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": {
    "hardware": {
     "accelerator": null,
     "gpuPoolId": null,
     "memory": null
    }
   },
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "dependencies": [
     "-r /Workspace/Users/real.anirvan@gmail.com/ai-agents-masterclass/requirements.txt"
    ],
    "environment_version": "3"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "1.3-call-tools-using-langraph",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
