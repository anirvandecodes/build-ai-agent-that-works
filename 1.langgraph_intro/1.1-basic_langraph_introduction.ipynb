{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4bc53b8b-6397-4e69-a865-054172ec5bc1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "![1.png](./images/langchain_and_langgraph.png \"1.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ac0875ce-2a46-4037-aab7-0ceeb7b97472",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "# Why Use Frameworks like LangChain & LangGraph?\n",
    "\n",
    "Even though you *can* write plain Python, frameworks help with things that get complicated fast:\n",
    "\n",
    "- **Workflow Management:** Organize multi-step tasks, agents, and APIs cleanly.  \n",
    "- **State Management:** Keep track of variables, context, or intermediate results across steps.  \n",
    "- **Memory:** Remember past interactions or user inputs for smarter responses.  \n",
    "- **Retries & Error Handling:** Automatically retry failed steps or handle exceptions.  \n",
    "- **Reusability & Maintainability:** Reuse components, swap models/tools without rewriting everything.  \n",
    "- **Dynamic Logic & Branching:** Easily implement loops, conditional paths, and agent collaboration.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2e5ed5bc-a749-4143-bdc1-c52bec0dc00b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c6f4d6aa-724f-4bf6-8973-a0d25206f0f8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b74cceb7-b1a0-459e-bae4-579c9cb48623",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c41a9f66-9c18-47d9-9d47-fe7599fe8a2f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Basic use of LangChain\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5b2b4700-0383-4051-b92e-506f21dea100",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from databricks_langchain import ChatDatabricks\n",
    "\n",
    "# Initialize model\n",
    "llm = ChatDatabricks(endpoint=\"databricks-gpt-oss-120b\")\n",
    "\n",
    "print(llm.invoke(\"What is Databricks?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0bbfbb38-a0cd-473d-be04-ac0142150fef",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7da64770-8e27-4b49-a78f-2b723e7dc3ba",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b74940ce-3947-4ccd-8ecc-9ec63b5fd8d7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7abf8ea2-182c-4640-912e-579f214bb631",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "54949965-f9e6-494f-88d4-4f6a8c4a152f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c779bbfa-788e-44dd-9938-d6e389e379c1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8da1c97a-23b7-4cfd-ab75-6acfa8dc5dad",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from databricks_langchain import ChatDatabricks\n",
    "from langchain_core.messages import HumanMessage, AIMessage\n",
    "import json\n",
    "\n",
    "# Initialize model\n",
    "llm = ChatDatabricks(endpoint=\"databricks-gpt-oss-120b\")\n",
    "\n",
    "# Store all messages\n",
    "messages = []\n",
    "\n",
    "# 1ï¸âƒ£ User message\n",
    "user_msg = HumanMessage(content=\"What is Databricks?\")\n",
    "messages.append(user_msg)\n",
    "\n",
    "# 2ï¸âƒ£ Model response\n",
    "response = llm.invoke(messages)\n",
    "\n",
    "# Save response\n",
    "messages.append(AIMessage(content=response.content))\n",
    "\n",
    "# 3ï¸âƒ£ Print everything nicely\n",
    "print(\"\\n--- All messages so far ---\")\n",
    "for m in messages:\n",
    "    print(f\"\\n[{m.type.upper()} MESSAGE]\")\n",
    "    if isinstance(m.content, list):\n",
    "        # Print structured message (reasoning + text)\n",
    "        for part in m.content:\n",
    "            print(f\"  - Type: {part.get('type')}\")\n",
    "            if 'summary' in part:\n",
    "                print(\"    Summary:\")\n",
    "                print(json.dumps(part['summary'], indent=4))\n",
    "            if 'text' in part:\n",
    "                print(\"    Text:\")\n",
    "                print(part['text'][:1000])  # truncate long text for readability\n",
    "    else:\n",
    "        # Simple message (string)\n",
    "        print(m.content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "359088b7-3588-4451-bba6-f99d900a59b1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "\n",
    "**Databricks** is a cloudâ€‘native dataâ€‘andâ€‘AI platform built around **Apacheâ€¯Spark** that provides a unified workspace for data engineering, data science, machine learning (ML), and analytics. It combines a managed Spark service with a collaborative notebook environment, a dataâ€‘lakehouse architecture, and a suite of tools for the entire data lifecycle.\n",
    "\n",
    "---\n",
    "\n",
    "## 1. Core Idea â€“ the â€œLakehouseâ€\n",
    "| Concept | Traditional Approach | Databricksâ€™ Approach |\n",
    "|---------|----------------------|----------------------|\n",
    "| **Data storage** | Separate data warehouse (structured) + data lake (raw files) | **Lakehouse**: a single openâ€‘format storage layer (Deltaâ€¯Lake) that offers both ACID transactions (warehouseâ€‘like guarantees) and lowâ€‘cost objectâ€‘store scalability (lakeâ€‘like). |\n",
    "| **Governance** | Multiple tools, fragmented metadata | **Unityâ€¯Catalog** (centralized metadata, fineâ€‘grained access control). |\n",
    "| **Performance** | Queries on warehouse are fast; lake queries are slower | **Deltaâ€¯Lake** + **P"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2a104828-e691-46e1-bef9-96e74ea12e91",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# ðŸ§© Simple StateGraph Workflow â€” Concepts Explained\n",
    "\n",
    "This code creates a **state-based workflow** using LangGraph. Instead of calling functions directly in sequence, we define:\n",
    "\n",
    "- A **State**: a typed dictionary (`TypedDict`) that describes what data flows between nodes (`graph_state` in this case).\n",
    "- **Nodes**: plain Python functions (`node_1`, `node_2`, `node_3`) that:\n",
    "  - Receive the current `state` (a dict)\n",
    "  - Perform some operation (here, just string concatenation)\n",
    "  - Return an updated `state` (partial dict with changed values)\n",
    "\n",
    "- A **StateGraph**: an object that stores the nodes and how they connect.\n",
    "  - We add each node to the graph by name.\n",
    "  - We define **edges** between nodes â€” this describes the execution path (`START â†’ node_1 â†’ node_2 â†’ node_3 â†’ END`).\n",
    "\n",
    "- **Compilation**: `builder.compile()` turns the defined graph into an executable workflow.\n",
    "- **Visualization**: `graph.get_graph().draw_mermaid_png()` renders a diagram of the graph so you can see the structure visually in the notebook.\n",
    "\n",
    "**Conceptually:**  \n",
    "This pattern abstracts workflows into **directed graphs**. Each node is independent, the graph controls the order, and the shared `state` moves through the graph â€” a foundation for building more complex, branching, or parallel agent systems.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a03cb8ac-5eda-46a7-baf5-372791fe29a4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import random\n",
    "from typing import Literal, TypedDict\n",
    "from langchain_core.messages import AnyMessage, HumanMessage\n",
    "from langgraph.graph.message import add_messages\n",
    "from typing_extensions import Annotated\n",
    "from databricks_langchain import ChatDatabricks\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.prebuilt import ToolNode, tools_condition\n",
    "from IPython.display import Image, display\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "\n",
    "\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "class State(TypedDict):\n",
    "    graph_state: str\n",
    "\n",
    "def node_1(state):\n",
    "    print(\"---Node 1---\")\n",
    "    return {\"graph_state\": state['graph_state'] +\" I am\"}\n",
    "\n",
    "def node_2(state):\n",
    "    print(\"---Node 2---\")\n",
    "    return {\"graph_state\": state['graph_state'] +\" happy!\"}\n",
    "\n",
    "def node_3(state):\n",
    "    print(\"---Node 3---\")\n",
    "    return {\"graph_state\": state['graph_state'] +\" sad!\"}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Build graph\n",
    "builder = StateGraph(State)\n",
    "builder.add_node(\"node_1\", node_1)\n",
    "builder.add_node(\"node_2\", node_2)\n",
    "builder.add_node(\"node_3\", node_3)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Logic\n",
    "builder.add_edge(START, \"node_1\")\n",
    "builder.add_edge(\"node_1\", \"node_2\")\n",
    "builder.add_edge(\"node_2\", \"node_3\")\n",
    "builder.add_edge(\"node_3\", END)\n",
    "\n",
    "# Add\n",
    "graph = builder.compile()\n",
    "\n",
    "# View\n",
    "display(Image(graph.get_graph().draw_mermaid_png(max_retries=5, retry_delay=2.0)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e92d8d04-bd6f-4aa8-9b7b-3ecf9720be48",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "graph.invoke({\"graph_state\" : \"Hi, this is Anirvan.\"})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "df9f6ad1-13a8-4aef-beee-ce4eb62ff9e7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# ðŸ”€ Conditional Branching in a LangGraph Workflow\n",
    "\n",
    "In this example, we introduce **dynamic decision-making** into our StateGraph. Instead of always following a fixed sequence, a node can decide which next node to run at runtime.\n",
    "\n",
    "We do this in three steps:\n",
    "\n",
    "1. **Decision Function**  \n",
    "   We create a Python function (here called `decide_mood`) that takes the current `state` and returns the name of the next node.  \n",
    "   In this demo, it just flips a coin: 50% chance to go to `node_2`, 50% to `node_3`. In a real project, this function could look at values in `state` (like user input, an LLM output, or an API response) to pick the right branch.\n",
    "\n",
    "2. **Attach Conditional Edges**  \n",
    "   Instead of a normal `add_edge`, we use `add_conditional_edges(\"node_1\", decide_mood)`.  \n",
    "   This tells LangGraph: after running `node_1`, call `decide_mood(state)` and follow whatever node name it returns. This is how branching logic is added without hardcoding paths.\n",
    "\n",
    "3. **Complete the Graph**  \n",
    "   Both possible branches (`node_2` and `node_3`) are then connected to `END`. This ensures no matter which branch is chosen, the workflow eventually terminates cleanly.\n",
    "\n",
    "**Conceptually:**  \n",
    "- Nodes still work the same way â€” they process and update the `state`.  \n",
    "- The graph itself becomes more flexible, able to handle different paths dynamically.  \n",
    "- This pattern is the foundation for routers, conditional processing, or any workflow that depends on runtime data to decide the next step.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dda069e4-ef2f-4908-b4da-93d73ce5e2a0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import random\n",
    "from typing import Literal\n",
    "\n",
    "def decide_mood(state) -> Literal[\"node_2\", \"node_3\"]:\n",
    "    \n",
    "    # Often, we will use state to decide on the next node to visit\n",
    "    user_input = state['graph_state'] \n",
    "    \n",
    "    # Here, let's just do a 50 / 50 split between nodes 2, 3\n",
    "    if random.random() < 0.5:\n",
    "\n",
    "        # 50% of the time, we return Node 2\n",
    "        return \"node_2\"\n",
    "    \n",
    "    # 50% of the time, we return Node 3\n",
    "    return \"node_3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b51af6fa-611a-428a-aa70-3aa7495dcd3c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9ad42192-a9d3-4cb9-acf3-9b73c236ab0b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "526d4338-7c3d-44ca-a775-70a09c6898b8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Build graph\n",
    "builder1 = StateGraph(State)\n",
    "builder1.add_node(\"node_1\", node_1)\n",
    "builder1.add_node(\"node_2\", node_2)\n",
    "builder1.add_node(\"node_3\", node_3)\n",
    "\n",
    "# Logic\n",
    "builder1.add_edge(START, \"node_1\")\n",
    "builder1.add_conditional_edges(\"node_1\", decide_mood)\n",
    "builder1.add_edge(\"node_2\", END)\n",
    "builder1.add_edge(\"node_3\", END)\n",
    "\n",
    "# Add\n",
    "graph1 = builder1.compile()\n",
    "\n",
    "# View\n",
    "display(Image(graph.get_graph().draw_mermaid_png(max_retries=5, retry_delay=2.0)))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "71b5dcbc-7aa5-446e-adcf-09d269d70607",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "graph1.invoke({\"graph_state\" : \"Hi, this is Anirvan.\"})\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": {
    "hardware": {
     "accelerator": null,
     "gpuPoolId": null,
     "memory": null
    }
   },
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "dependencies": [
     "-r /Workspace/Users/real.anirvan@gmail.com/build-ai-agent-that-works/requirements.txt"
    ],
    "environment_version": "3"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "1.1-basic_langraph_introduction",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
