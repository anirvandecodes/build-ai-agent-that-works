{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "eb12ca16-abbe-4597-a69d-a0fa95b2afac",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from typing import Literal, TypedDict\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "from langgraph.graph.message import add_messages\n",
    "from typing_extensions import Annotated\n",
    "from databricks_langchain import ChatDatabricks\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.graph import MessagesState\n",
    "\n",
    "# Initialize LLM\n",
    "llm = ChatDatabricks(endpoint=\"databricks-gpt-oss-120b\")\n",
    "\n",
    "def call_llm(state: MessagesState):\n",
    "    \"\"\"Node to call the LLM with a formatted prompt based on the latest user question.\"\"\"\n",
    "    \n",
    "    \n",
    "    # Build the prompt\n",
    "    prompt_template = (\n",
    "        \"You are an expert AI assistant. Answer the user's question with clarity, accuracy, and conciseness.\\n\\n\"\n",
    "        \"## Question:\\n\"\n",
    "        \"{question}\\n\\n\"\n",
    "        \"## Guidelines:\\n\"\n",
    "        \"- Keep responses factual and to the point.\\n\"\n",
    "        \"- If relevant, provide examples or step-by-step instructions.\\n\"\n",
    "        \"- If the question is ambiguous, clarify before answering.\\n\\n\"\n",
    "        \"Respond below:\"\n",
    "    )\n",
    "    formatted_prompt = prompt_template.format(question=state['messages'])\n",
    "\n",
    "    # Construct the message list for the model\n",
    "    all_msgs = [\n",
    "        SystemMessage(content=\"You are an expert AI assistant.\"),\n",
    "        HumanMessage(content=formatted_prompt)\n",
    "    ]\n",
    "\n",
    "    # Call the LLM\n",
    "    response = llm.invoke(all_msgs)\n",
    "\n",
    "    return {\"messages\": state[\"messages\"] + [response]}\n",
    "\n",
    "# Build the graph\n",
    "builder = StateGraph(MessagesState)\n",
    "builder.add_node(\"call_llm\", call_llm)\n",
    "\n",
    "builder.add_edge(START, \"call_llm\")\n",
    "builder.add_edge(\"call_llm\", END)\n",
    "\n",
    "graph = builder.compile()\n",
    "\n",
    "# Example run\n",
    "messages = graph.invoke({\n",
    "    \"messages\": [HumanMessage(content=\"What is the return policy for Anirvan Decodes ecommerce products?\")]\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cc628c1f-fb86-480c-a923-04affb8ba5dd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "message = messages['messages'][-1]\n",
    "\n",
    "for part in message.content:\n",
    "    if part.get(\"type\") == \"text\":\n",
    "       ai_message = part.get(\"text\", \"\")\n",
    "\n",
    "print(ai_message)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": {
    "hardware": {
     "accelerator": null,
     "gpuPoolId": null,
     "memory": null
    }
   },
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "dependencies": [
     "-r /Workspace/Users/real.anirvan@gmail.com/ai-agents-masterclass/requirements.txt"
    ],
    "environment_version": "3"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "2.1-Why knowledge assistant",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
