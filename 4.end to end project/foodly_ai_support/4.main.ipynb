{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a53aff84-47dd-4932-ad68-264717ab0ab3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "import json\n",
    "from typing import Annotated, Any, Generator, Optional, Sequence, TypedDict, Union\n",
    "from uuid import uuid4\n",
    "\n",
    "import mlflow\n",
    "from databricks_langchain import (\n",
    "    ChatDatabricks,\n",
    "    UCFunctionToolkit,\n",
    "    VectorSearchRetrieverTool,\n",
    ")\n",
    "from langchain_core.language_models import LanguageModelLike\n",
    "from langchain_core.messages import (\n",
    "    AIMessage,\n",
    "    AIMessageChunk,\n",
    "    BaseMessage,\n",
    "    convert_to_openai_messages,\n",
    ")\n",
    "from langchain_core.runnables import RunnableConfig, RunnableLambda\n",
    "from langchain_core.tools import BaseTool\n",
    "from langgraph.graph import END, StateGraph\n",
    "from langgraph.graph.message import add_messages\n",
    "from langgraph.prebuilt.tool_node import ToolNode\n",
    "from mlflow.entities import SpanType\n",
    "from mlflow.pyfunc import ResponsesAgent\n",
    "from mlflow.types.responses import (\n",
    "    ResponsesAgentRequest,\n",
    "    ResponsesAgentResponse,\n",
    "    ResponsesAgentStreamEvent,\n",
    ")\n",
    "\n",
    "LLM_ENDPOINT_NAME = \"databricks-meta-llama-3-3-70b-instruct\"\n",
    "llm = ChatDatabricks(endpoint=LLM_ENDPOINT_NAME)\n",
    "\n",
    "tools = []\n",
    "\n",
    "# uc function tools\n",
    "UC_TOOL_NAMES = [\"agents.escalation.escalate_to_human\", \"agents.orders_data.cancel_order\", \"agents.orders_data.get_all_orders\", \"agents.orders_data.get_order_details\", \"agents.orders_data.get_order_status\"]\n",
    "uc_toolkit = UCFunctionToolkit(function_names=UC_TOOL_NAMES)\n",
    "tools.extend(uc_toolkit.tools)\n",
    "\n",
    "# Initialize the retriever tool.\n",
    "VECTOR_SEARCH_TOOL = VectorSearchRetrieverTool(\n",
    "    index_name=\"agents.main.foodly_policy_embedding_index\",\n",
    "    tool_name=\"foodly_policy_document_retrieval_tool\",\n",
    "    num_results=2,\n",
    "    tool_description=\"Use this tool to search the Foodly knowledge base for policies, procedures, and service-related information. It retrieves the most relevant chunks from the company’s official documentation, including refund rules, cancellation terms, delivery guidelines, loyalty program details, privacy policies, and escalation procedures\"\n",
    ")\n",
    "tools.append(VECTOR_SEARCH_TOOL)\n",
    "\n",
    "system_prompt = \"\"\"\n",
    "You are Foodly Support Agent.\n",
    "\n",
    "You handle all user questions and issues related to Foodly:\n",
    "- Orders: list, check status, show details, cancel\n",
    "- Policies: refunds, cancellations, loyalty, delivery, safety, privacy, promotions\n",
    "- Refunds: initiate or check status\n",
    "- Escalation: when user requests a human\n",
    "\n",
    "Use the provided tools to fetch or update information.\n",
    "Never make up answers.\n",
    "If a tool call fails or required information (like order ID or user ID) is missing, ask the user for what’s missing and wait for their reply.\n",
    "Only escalate when the user explicitly asks for a human or when no tool can solve the issue.\n",
    "\n",
    "Keep replies short, clear, friendly, and safe.\n",
    "\"\"\"\n",
    "\n",
    "from helpers import LangGraphResponsesAgent, create_tool_calling_agent\n",
    "mlflow.langchain.autolog()\n",
    "agent = create_tool_calling_agent(llm, tools, system_prompt)\n",
    "AGENT = LangGraphResponsesAgent(agent)\n",
    "mlflow.models.set_model(AGENT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "800f5ed9-dbd9-4481-823c-74f948c3d4d7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "for chunk in AGENT.predict_stream(\n",
    "    {\"input\": [{\"role\": \"user\", \"content\": \"where is my order?\"}]}\n",
    "):\n",
    "    print(chunk.model_dump(exclude_none=True))"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": {
    "hardware": {
     "accelerator": null,
     "gpuPoolId": null,
     "memory": null
    }
   },
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "dependencies": [
     "-r /Workspace/Users/real.anirvan@gmail.com/ai-agents-masterclass/requirements.txt"
    ],
    "environment_version": "3"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "4.main",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
