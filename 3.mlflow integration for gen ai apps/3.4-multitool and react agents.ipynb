{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f76cb3ec-a4fa-43a6-9543-9d2954104ea3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "# ReAct Agent with LangGraph - Reasoning and Acting Pattern\n",
    "\n",
    "This code creates a **ReAct (Reasoning and Acting) agent** using LangGraph's prebuilt functionality, which combines **reasoning** and **tool usage** in an iterative loop.\n",
    "\n",
    "## 🔧 **Setup & Configuration**\n",
    "```python\n",
    "LLM_ENDPOINT_NAME = \"databricks-meta-llama-3-3-70b-instruct\"\n",
    "llm = ChatDatabricks(endpoint=LLM_ENDPOINT_NAME)\n",
    "system_prompt = \"You are a helpful assistant that can run Python code.\"\n",
    "```\n",
    "- **LLM**: Databricks Llama 3.3 70B model\n",
    "- **System prompt**: Defines the agent's behavior\n",
    "\n",
    "## 🛠️ **Simple Tool Definitions**\n",
    "```python\n",
    "def get_weather(city: str) -> str:\n",
    "    \"\"\"Get weather for a given city.\"\"\"\n",
    "    return f\"The weather in {city} is sunny.\"\n",
    "\n",
    "def get_time(zone: str) -> str:\n",
    "    \"\"\"Get current time for a given timezone.\"\"\"\n",
    "    return f\"The current time in {zone} is 2:00 PM.\"\n",
    "```\n",
    "- **Simple functions**: Basic weather and time tools\n",
    "- **Docstrings**: Help the LLM understand what each tool does\n",
    "- **Mock responses**: Return static responses for demonstration\n",
    "\n",
    "## 🤖 **ReAct Agent Creation**\n",
    "```python\n",
    "agent_graph = create_react_agent(\n",
    "    model=llm,\n",
    "    tools=tools,\n",
    "    prompt=system_prompt\n",
    ")\n",
    "```\n",
    "**Key advantage**: One-line agent creation using LangGraph's prebuilt ReAct implementation\n",
    "\n",
    "## 🔄 **How ReAct Works**\n",
    "The ReAct pattern follows this loop:\n",
    "\n",
    "1. **Thought**: LLM reasons about the user's question\n",
    "2. **Action**: Decides which tool to use (or if to respond directly)\n",
    "3. **Observation**: Sees the tool's result\n",
    "4. **Repeat**: Continues reasoning until it has enough information\n",
    "5. **Answer**: Provides final response to the user\n",
    "\n",
    "**Example Flow**:\n",
    "\n",
    "\n",
    "**Example Flow**:\n",
    "1. **User**: \"What's the weather in Paris and what time is it in Tokyo?\"\n",
    "2. **Thought**: I need to get weather for Paris and time for Tokyo\n",
    "3. **Action**: get_weather(\"Paris\")\n",
    "4. **Observation**: \"The weather in Paris is sunny\"\n",
    "5. **Thought**: Now I need the time in Tokyo\n",
    "6. **Action**: get_time(\"Tokyo\") \n",
    "7. **Observation**: \"The current time in Tokyo is 2:00 PM\"\n",
    "8. **Thought**: I have both pieces of information now\n",
    "9. **Answer**: \"The weather in Paris is sunny and it's 2:00 PM in Tokyo\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## 🎯 **Key Benefits of ReAct Pattern**\n",
    "- **Iterative reasoning**: Can use multiple tools in sequence\n",
    "- **Self-correction**: Can reason about tool results and adjust\n",
    "- **Transparency**: Shows its \"thinking\" process\n",
    "- **Flexible**: Can handle complex multi-step problems\n",
    "- **Automatic**: LangGraph handles the reasoning loop\n",
    "\n",
    "## 🚀 **Prebuilt Advantage**\n",
    "Instead of manually building the graph with nodes and edges, `create_react_agent()`:\n",
    "- **Auto-creates** the reasoning loop\n",
    "- **Handles** tool calling logic\n",
    "- **Manages** state transitions\n",
    "- **Provides** built-in ReAct prompting\n",
    "\n",
    "This makes creating sophisticated reasoning agents incredibly simple compared to building the graph manually."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "94b014ff-f2db-4672-b481-d54ff44ee4fe",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Using langraph create_react_agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "80b356b8-832a-4c20-b657-ee6390749c44",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "from typing import Any, Generator\n",
    "from uuid import uuid4\n",
    "\n",
    "import mlflow\n",
    "from databricks_langchain import ChatDatabricks, UCFunctionToolkit\n",
    "from langchain_core.messages import AIMessageChunk\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "\n",
    "from mlflow.pyfunc import ResponsesAgent\n",
    "from mlflow.types.responses import (\n",
    "    ResponsesAgentRequest,\n",
    "    ResponsesAgentResponse,\n",
    "    ResponsesAgentStreamEvent,\n",
    ")\n",
    "\n",
    "############################################\n",
    "# Define LLM and tools\n",
    "############################################\n",
    "LLM_ENDPOINT_NAME = \"databricks-meta-llama-3-3-70b-instruct\"\n",
    "llm = ChatDatabricks(endpoint=LLM_ENDPOINT_NAME)\n",
    "\n",
    "# UC_TOOL_NAMES = [\"system.ai.python_exec\"]\n",
    "# uc_toolkit = UCFunctionToolkit(function_names=UC_TOOL_NAMES)\n",
    "# tools = uc_toolkit.tools\n",
    "\n",
    "\n",
    "def get_weather(city: str) -> str:\n",
    "    \"\"\"Get weather for a given city.\"\"\"\n",
    "    return f\"The weather in {city} is sunny.\"\n",
    "\n",
    "def get_time(zone: str) -> str:\n",
    "    \"\"\"Get current time for a given timezone.\"\"\"\n",
    "    return f\"The current time in {zone} is 2:00 PM.\"\n",
    "\n",
    "\n",
    "    \n",
    "  \n",
    "\n",
    "tools = [get_weather,get_time]\n",
    "\n",
    "system_prompt = \"You are a helpful assistant that can run Python code.\"\n",
    "\n",
    "############################################\n",
    "# Build the ReAct agent automatically\n",
    "############################################\n",
    "agent_graph = create_react_agent(\n",
    "    model=llm,\n",
    "    tools=tools,\n",
    "    prompt=system_prompt,  # this injects your system prompt\n",
    ")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "23d0101f-cc65-4368-8abb-3a9aa4280a2c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "############################################\n",
    "# Register the agent with MLflow\n",
    "############################################\n",
    "from helpers import LangGraphResponsesAgent\n",
    "mlflow.langchain.autolog()\n",
    "AGENT = LangGraphResponsesAgent(agent_graph)\n",
    "mlflow.models.set_model(AGENT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e1a8a26a-0edc-4874-8638-b44c92db6906",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "result = AGENT.predict({\"input\": [{\"role\": \"user\", \"content\": \"What’s the weather in Paris and the time in EST? and search wikipedia for fun facts about paris\"}]})\n",
    "print(result.model_dump(exclude_none=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1dbac0de-ab91-4e56-90d3-e8ed02f4ec16",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "https://python.langchain.com/docs/integrations/tools/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e3725c97-40ce-43ad-a1ed-8b7c9ba8a337",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from langchain_community.tools import WikipediaQueryRun\n",
    "from langchain_community.utilities import WikipediaAPIWrapper\n",
    "\n",
    "\n",
    "# --- create Wikipedia tool ---\n",
    "wiki = WikipediaQueryRun(api_wrapper=WikipediaAPIWrapper())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "84fe75fa-b708-49c1-af6f-fff0a3617089",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "tools = [get_weather,get_time,wiki]\n",
    "\n",
    "prompt = \"\"\"\n",
    "You are a helpful AI assistant. You can think step-by-step and use the following tools to answer user questions:\n",
    "\n",
    "1. get_weather(city: str) — returns the current weather in the given city.\n",
    "2. get_time(zone: str) — returns the current time for the given timezone.\n",
    "3. WikipediaQueryRun(input: str) — searches Wikipedia and returns relevant information.\n",
    "\n",
    "Rules:\n",
    "- If a question needs factual information or background knowledge, prefer WikipediaQueryRun.\n",
    "- If the user asks about weather, use get_weather.\n",
    "- If the user asks about time, use get_time.\n",
    "- Always return a clear final answer to the user after using tools.\n",
    "- Think carefully about which tool is best for each part of the question. \n",
    "- You can use multiple tools in one conversation if the question needs it.\n",
    "- Do not guess values you can fetch with a tool — always call the correct tool.\n",
    "\n",
    "Follow the ReAct pattern:\n",
    "- First, think about what is needed.\n",
    "- Then, call the right tool with correct arguments.\n",
    "- Finally, summarize the result back to the user.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "############################################\n",
    "# Build the ReAct agent automatically\n",
    "############################################\n",
    "agent_graph = create_react_agent(\n",
    "    model=llm,\n",
    "    tools=tools,\n",
    "    prompt=prompt,  # this injects your system prompt\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c6ec4200-47f8-4738-8911-3f9ac1a00ed6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "############################################\n",
    "# Register the agent with MLflow\n",
    "############################################\n",
    "from helpers import LangGraphResponsesAgent\n",
    "mlflow.langchain.autolog()\n",
    "AGENT = LangGraphResponsesAgent(agent_graph)\n",
    "mlflow.models.set_model(AGENT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "57596951-11b1-4a77-a8c7-b53efcbf097d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "result = AGENT.predict({\"input\": [{\"role\": \"user\", \"content\": \"What’s the weather in Paris and the time in EST? and search wikipedia for fun facts about paris\"}]})\n",
    "print(result.model_dump(exclude_none=True))"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": {
    "hardware": {
     "accelerator": null,
     "gpuPoolId": null,
     "memory": null
    }
   },
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "dependencies": [
     "-r /Workspace/Users/real.anirvan@gmail.com/ai-agents-masterclass/requirements.txt"
    ],
    "environment_version": "3"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 2
   },
   "notebookName": "3.4-multitool and react agents",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
